import requests
import json
import hashlib
import configparser
import re
import os  # å¯¼å…¥osæ¨¡å—

headers = {'User-Agent': 'okhttp/3.15'}

def save_website_content_as_json_and_check_updates(url, file_name):
    config = configparser.ConfigParser()
    config.read(os.path.join("fan", "FatCat", "config.ini"))  # ä½¿ç”¨os.path.joinç¡®ä¿è·¯å¾„æ­£ç¡®
    
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            data = response.json()  # å‡è®¾å“åº”å†…å®¹æ˜¯JSONæ ¼å¼

            # è®¡ç®—è¿”å›æ•°æ®çš„md5å€¼æ¥æ£€æŸ¥æ•°æ®æ˜¯å¦æœ‰æ›´æ–°
            new_md5 = hashlib.md5(json.dumps(data, sort_keys=True).encode('utf-8')).hexdigest()
            old_md5 = config.get('DEFAULT', 'md5', fallback='')
            if new_md5 != old_md5:
                print("æ£€æµ‹åˆ°æ›´æ–°ã€‚")
                # æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„md5å€¼
                config['DEFAULT']['md5'] = new_md5
                with open(os.path.join("fan", "FatCat", "config.ini"), 'w') as configfile:
                    config.write(configfile)

                # ç›´æ¥åœ¨dataå­—å…¸ä¸Šä¿®æ”¹spiderå­—æ®µçš„å€¼
                if 'spider' in data:
                    original_url = data['spider'].split(';md5;')[0]  # å‡è®¾spiderå­—æ®µçš„æ ¼å¼ä¸º"URL;md5;MD5å€¼"
                    data['spider'] = data['spider'].replace(original_url, './fan/FatCat/PandaQ240609.jar')

                # å°†ä¿®æ”¹åçš„dataä¿å­˜ä¸ºJSONæ–‡ä»¶
                with open(file_name + '.json', 'w', encoding='utf-8') as file:
                    json.dump(data, file, indent=4, ensure_ascii=False)
                print(f"æ•°æ®å·²ä»¥JSONæ ¼å¼ä¿å­˜åˆ°{file_name}.json")
                
                # ä»JSONæ•°æ®ä¸­æå–åŒ…å«jaræ–‡ä»¶URLå’Œmd5å€¼çš„"spider"å­—æ®µ
                spider = data.get('spider')
                if spider:
                    match = re.match(r'http://[^/]+/jar/(.+?);md5;([a-f0-9]{32})', spider)
                    if match:
                        jar_url, jar_md5 = match.groups()
                        full_jar_url = f"http://like.xn--z7x900a.com/jar/{jar_url}"
                        # ä¸‹è½½jaræ–‡ä»¶
                        jar_response = requests.get(full_jar_url)
                        if jar_response.status_code == 200:
                            jar_file_name = jar_url.split('/')[-1]  # ä»URLæå–æ–‡ä»¶å
                            with open(os.path.join("fan", "FatCat", jar_file_name), 'wb') as jar_file:
                                jar_file.write(jar_response.content)
                            print(f"jaræ–‡ä»¶å·²ä¸‹è½½åˆ°ï¼š{jar_file_name}")
                            config['DEFAULT']['jar_md5'] = jar_md5
                            with open(os.path.join("fan", "FatCat", "config.ini"), 'w') as configfile:
                                config.write(configfile)
                            print("jaræ–‡ä»¶çš„md5å€¼å·²æ›´æ–°ã€‚")
                        else:
                            print(f"jaræ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{jar_response.status_code}")
                    else:
                        print("spiderå­—æ®µæ ¼å¼ä¸åŒ¹é…ã€‚")
            else:
                print("æœªæ£€æµ‹åˆ°æ›´æ–°ã€‚")
        else:
            print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")

# ç›®æ ‡URL
url = 'http://è‚¥çŒ«.com'
# æ–‡ä»¶åï¼Œä¸åŒ…æ‹¬æ‰©å±•å
file_name = 'website_content'

save_website_content_as_json_and_check_updates(url, file_name)

def modify_content(content):   # æ›´æ”¹è‡ªå®šä¹‰
    # Replace specified key and name  æ›¿æ¢"key":"è±†è±†","name":"å…¨æ¥å£æ™ºèƒ½è¿‡æ»¤å¹¿å‘Š" ä¸º"key":"è±†è±†","name":"æ™ºèƒ½AIå¹¿å‘Šè¿‡æ»¤"
    content = re.sub(r'{""key": "drpy_js_è±†ç“£","name": "ğŸ¼â”ƒå…¬ä¼—å·â”ƒè‚¥çŒ«å®è´",', r'{"key":"è±†è±†","name":"æ™ºèƒ½AIå¹¿å‘Šè¿‡æ»¤",', content)
    
    # åˆ é™¤ //{"key":  æ•´è¡Œ
    #content = re.sub(r'^\s*//\{"key":.*\n', '', content, flags=re.MULTILINE)

    # æ›¿æ¢"logo"URL
    #new_logo_url = "https://ghproxy.net/https://raw.githubusercontent.com/ne7359/url/main/fan/AW1.gif"
    #content = re.sub(r'"logo":"[^"]+"', f'"logo":"{new_logo_url}"', content)

    # æ›¿æ¢"live"URL
    #original_url = "https://www.huichunniao.cn/xh/lib/live.txt"
    #replacement_url = "https://fs-im-kefu.7moor-fs1.com/ly/4d2c3f00-7d4c-11e5-af15-41bf63ae4ea0/1715581924111/live1.txt"
    #content = content.replace(original_url, replacement_url)

    return content
