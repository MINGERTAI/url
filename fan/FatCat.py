import requests
import json
import hashlib
import configparser
import re
import os

headers = {'User-Agent': 'okhttp/3.15'}

def save_website_content_as_json_and_check_updates(url, file_name):
    # å®šä¹‰é…ç½®æ–‡ä»¶å’Œjaræ–‡ä»¶çš„ä¿å­˜è·¯å¾„
    config_directory = os.path.join("fan", "FatCat")
    config_path = os.path.join(config_directory, "config.ini")
    
    # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
    if not os.path.exists(config_directory):
        os.makedirs(config_directory)
    
    # è¯»å–é…ç½®æ–‡ä»¶
    config = configparser.ConfigParser()
    config.read(config_path)
    
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            data = response.json()

            new_md5 = hashlib.md5(json.dumps(data, sort_keys=True).encode('utf-8')).hexdigest()
            old_md5 = config.get('DEFAULT', 'md5', fallback='')
            if new_md5 != old_md5:
                print("æ£€æµ‹åˆ°æ›´æ–°ã€‚")
                # æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„md5å€¼
                config['DEFAULT']['md5'] = new_md5
                with open(config_path, 'w') as configfile:
                    config.write(configfile)
                
                spider = data.get('spider')
                if spider:
                    jar_match = re.match(r'http://[^/]+/jar/(.+?);md5;([a-f0-9]{32})', spider)
                    if jar_match:
                        jar_url, jar_md5 = jar_match.groups()
                        full_jar_url = f"http://like.xn--z7x900a.com/jar/{jar_url}"
                        jar_response = requests.get(full_jar_url)
                        if jar_response.status_code == 200:
                            jar_file_name = jar_url.split('/')[-1]
                            # æ„å»ºjaræ–‡ä»¶çš„å®Œæ•´ä¿å­˜è·¯å¾„
                            jar_file_path = os.path.join(config_directory, jar_file_name)
                            with open(jar_file_path, 'wb') as jar_file:
                                jar_file.write(jar_response.content)
                            print(f"jaræ–‡ä»¶å·²ä¸‹è½½åˆ°ï¼š{jar_file_path}")
                            # æ›´æ–°é…ç½®æ–‡ä»¶
                            config['DEFAULT']['jar_md5'] = jar_md5
                            with open(config_path, 'w') as configfile:
                                config.write(configfile)
                            print("jaræ–‡ä»¶çš„md5å€¼å·²æ›´æ–°ã€‚")
                        else:
                            print(f"jaræ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{jar_response.status_code}")

                if 'spider' in data:
                    original_url = data['spider'].split(';md5;')[0]
                    data['spider'] = data['spider'].replace(original_url, f'./fan/FatCat/{jar_file_name}')
                
                # å°†ä¿®æ”¹åçš„dataä¿å­˜ä¸ºJSONæ–‡ä»¶
                with open(file_name + '.json', 'w', encoding='utf-8') as file:
                    json.dump(data, file, indent=4, ensure_ascii=False)
                print(f"æ•°æ®å·²ä»¥JSONæ ¼å¼ä¿å­˜åˆ° {file_name}.json")

                # å‡å®šè¿™æ˜¯è¦ä¿å­˜çš„æ•°æ®ç¤ºä¾‹
                new_data = [
                    {"key": "çŸ­å‰§", "name": "ğŸŒˆä¸Šå¤´â”ƒçŸ­å‰§", "type": 3, "api": "csp_Djuu", "searchable": 1, "quickSearch": 1, "changeable": 1},
                    {"key": "é…·çœ‹", "name": "ğŸ’¡é…·çœ‹â”ƒç§’æ’­", "type": 3, "api": "csp_Kkys", "timeout": 15, "searchable": 1, "quickSearch": 1, "changeable": 1},
                    {"key": "åŸåˆ›", "name": "â˜€åŸåˆ›â”ƒä¸å¡", "type": 3, "api": "csp_YCyz", "timeout": 15, "playerType": 1, "searchable": 1, "quickSearch": 1, "changeable": 1}
                ]

                # ç”ŸæˆJSONå­—ç¬¦ä¸²å¹¶ä¿å­˜åˆ°æ–‡ä»¶
                save_json_compact('1.json', new_data)
                
            else:
                print("æœªæ£€æµ‹åˆ°æ›´æ–°ã€‚")
        else:
            print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")

def save_json_compact(file_path, data):
    """å°†JSONæ•°æ®ä¿å­˜ä¸ºç´§å‡‘çš„ä¸€è¡Œæ ¼å¼"""
    json_str = json.dumps(data, ensure_ascii=False, separators=(',', ':'))
    with open(file_path, 'w', encoding='utf-8') as file:
        file.write(json_str)
    print(f"æ•°æ®å·²ä»¥ç´§å‡‘çš„JSONæ ¼å¼ä¿å­˜åˆ° {file_path}")

# ç›®æ ‡URL
url = 'http://è‚¥çŒ«.com'
# æ–‡ä»¶åï¼Œä¸åŒ…æ‹¬æ‰©å±•å
file_name = 'FatCat'

save_website_content_as_json_and_check_updates(url, file_name)
